{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Want to run this code for yourself?\n",
    "You can find the interactive ipython notebook where you can run all the steps listed here at\n",
    "\n",
    "https://mybinder.org/v2/gh/NanoNets/tutorials/master?filepath=ocr/notebooks/ocr.ipynb\n",
    "\n",
    "PS: it will take a couple of minutes for the mybinder instance to boot up and be ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "from multiprocessing import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper methods for creating, uploading data and training an object detection model.\n",
    "def create_new_model(base_url, auth_key, categories):\n",
    "    \"\"\"\n",
    "    function to create a new model for training\n",
    "    \n",
    "    Args:\n",
    "    base_url: url to nanonets endpoint which will decide what type of model to create\n",
    "    auth_key: authentication key provided by https://app.nanonets.com/#/keys\n",
    "    categories: List of labels you want to predict/ detect\n",
    "    \n",
    "    return:\n",
    "    model_id: a unique reference to new created model\n",
    "    \"\"\"\n",
    "    payload = json.dumps({\"categories\" : categories, \"model_type\": \"ocr\"})\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': \"application/json\",\n",
    "    }\n",
    "\n",
    "    response = requests.request(\n",
    "        \"POST\",\n",
    "        base_url,\n",
    "        headers=headers,\n",
    "        auth=requests.auth.HTTPBasicAuth(auth_key, ''),\n",
    "        data=payload,\n",
    "    )\n",
    "\n",
    "    result = json.loads(response.text)\n",
    "    print(\"Model Information: \", result)\n",
    "    model_id, model_type, categories = (result[\"model_id\"], result[\"model_type\"], result[\"categories\"])\n",
    "    return model_id\n",
    "\n",
    "def get_model_info(base_url, auth_key, model_id):\n",
    "    \"\"\"\n",
    "    function to get/ print information about model at any time\n",
    "    \n",
    "    Args:\n",
    "    base_url: url to nanonets endpoint which will decide what type of model to create\n",
    "    auth_key: authentication key provided by https://app.nanonets.com/#/keys\n",
    "    model_id: unique model_id generated at model creation time\n",
    "    \"\"\"\n",
    "    print('%s%s'%(base_url, model_id))\n",
    "    response = requests.request(\n",
    "        'GET',\n",
    "        '%s%s'%(base_url, model_id),\n",
    "        auth=requests.auth.HTTPBasicAuth(auth_key, '')\n",
    "    )\n",
    "    print(response.text)\n",
    "    result = json.loads(response.text)\n",
    "    model_id, model_type, categories, state = (result[\"model_id\"], result[\"model_type\"], result[\"categories\"], result[\"state\"])\n",
    "    return model_id, model_type, categories, state\n",
    "\n",
    "\n",
    "def generate_upload_data(image_file, annotation_info, model_id):\n",
    "    \"\"\"\n",
    "    function to translate image and annotation info into format suitable for upload\n",
    "    \n",
    "    Args:\n",
    "    image_file[str]: full path to where the image is located\n",
    "    annotation_info[str]: json formatted string of the ocr annotations in the image\n",
    "        eg. '[{\"name\": \"label_1\", \"bndbox\": {\"xmin\": 50, \"ymin\": 50, \"xmax\": 100, \"ymax\": 100}, \"ocr_text\": \"\"}, ...]'\n",
    "    model_id[str]: model id for which data needs to be uploaded\n",
    "    \n",
    "    Returns:\n",
    "    data[Dict[str, Any]]: data that can be passed onto to the upload data method \n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'file' : open(image_file, 'rb'),\n",
    "        'data' :('', '[{\"filename\":\"%s\", \"object\": %s}]' % (image_file.rsplit('/', 1)[1], annotation_info)),\n",
    "        'modelId' :('', '%s'% model_id),\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def upload_data(base_url, model_id, auth_key, data):\n",
    "    \"\"\"\n",
    "    function to upload data for a model that has been created\n",
    "    \n",
    "    Args:\n",
    "    base_url[str]: nanonets endpoint to which the model upload request will be sent\n",
    "        eg. https://app.nanonets.com/api/v2/ObjectDetection/Model/\n",
    "    model_id[str]: model id of the model for which data is being uploaded generated by calling the create_model method\n",
    "    auth_key[str]: authentication key provided by https://app.nanonets.com/#/keys\n",
    "    data[Dict[str, Any]]: dictionary recieved from the generate_upload_data method\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        '%s%s/UploadFile/'% (base_url, model_id),\n",
    "        auth=requests.auth.HTTPBasicAuth(auth_key, ''),\n",
    "        files=data,\n",
    "    )\n",
    "    print(response.text)\n",
    "    \n",
    "    \n",
    "def train_model(base_url, auth_key, model_id):\n",
    "\n",
    "    headers = {'authorization': 'Basic %s'%auth_key}\n",
    "    querystring = {'modelId': model_id}\n",
    "    response = requests.request(\n",
    "        'POST',\n",
    "        '%s%s/Train/'%(base_url, model_id),\n",
    "        headers=headers,\n",
    "        auth=requests.auth.HTTPBasicAuth(auth_key, ''),\n",
    "        params=querystring,\n",
    "    )\n",
    "    print(\"training started .... \")\n",
    "    print(json.loads(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "# OCR for Dummy Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSTANTS\n",
    "Some universal constants that we will need for creating new models, uploading data and launching training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_URL = \"https://app.nanonets.com/api/v2/ObjectDetection/Model/\"\n",
    "CATEGORIES = []  # if empty list labels will be automatically identified from annotations \n",
    "AUTH_KEY = \"<YOUR_NANONETS_API_KEY>\"  # can be foung https://app.nanonets.com/#/keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_model\n",
    "model_id = create_new_model(base_url=BASE_MODEL_URL, auth_key=AUTH_KEY, categories=CATEGORIES)\n",
    "\n",
    "print(\"New model created: \", model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and upload_data\n",
    "# change current working directory to location where object-detection-sample-python repo is cloned\n",
    "image_directory = <IMAGE_DIRECTORY>  # REPLACE WITH LOCAL FOLDER IF ALREADY EXISTS\n",
    "annotation_directory = <ANNOTATIONS_DIRECTORY>  # REPLACE WITH LOCAL FOLDER IF ALREADY EXISTS\n",
    "annotation_files = os.listdir(annotation_directory)\n",
    "\n",
    "\n",
    "# get the image and annotation info in format easy to upload\n",
    "image_and_annotations = []\n",
    "\n",
    "for annotation_file in annotation_files:\n",
    "    xml_path = os.path.join(annotation_directory, annotation_file)\n",
    "    # check corresponding image file exists\n",
    "    image_path = os.path.join(image_directory, os.path.basename(annotation_file).replace(\"xml\", \"jpeg\"))\n",
    "    if not os.path.exists(image_path):\n",
    "        # skipping annotation as image does not exist\n",
    "        continue\n",
    "\n",
    "    # parse XML file and convert into dictionary format we need\n",
    "    for anno in xml_info:\n",
    "        xml_to_json.append({\n",
    "            \"name\": <LABEL>,\n",
    "            \"bndbox\": {\"xmin\": <XMIN>, \"ymin\": <YMIN>, \"xmax\": <XMAX>, \"ymax\": <YMAX>},\n",
    "            \"ocr_text\": <OCR_TEXT>\n",  # OPTIONAL
    "        })\n",
    "    annotation_info = json.dumps(xml_to_json)\n",
    "    image_and_annotations.append((image_path, annotation_info, model_id))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload image and annotation using the previously built helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the data for the model to be trained, using multiprocessig to make data upload faster.\n",
    "def upload_data_multiprocessing(image_and_annotation):\n",
    "    image_file, annotation_info, model_id = image_and_annotation\n",
    "    data = generate_upload_data(image_file, annotation_info, model_id)\n",
    "    upload_data(BASE_MODEL_URL, model_id, AUTH_KEY, data)\n",
    "    \n",
    "\n",
    "p = Pool(4)\n",
    "p.map(upload_data_multiprocessing, image_and_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model info \n",
    "get_model_info(BASE_MODEL_URL, AUTH_KEY, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training for model once all data has been uploaded\n",
    "train_model(BASE_MODEL_URL, AUTH_KEY, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_info(BASE_MODEL_URL, AUTH_KEY, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
